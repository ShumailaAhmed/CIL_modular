{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./drive_interfaces/carla/carla_client/\")\n",
    "from carla.client import make_carla_client\n",
    "from carla.settings import CarlaSettings\n",
    "from carla.client import VehicleControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./drive_interfaces/carla/yang_template.ini\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from carla.sensor import Camera, Lidar\n",
    "settings = CarlaSettings()\n",
    "settings.set(\n",
    "    SynchronousMode=True,\n",
    "    SendNonPlayerAgentsInfo=True,\n",
    "    NumberOfVehicles=20,\n",
    "    NumberOfPedestrians=40,\n",
    "    WeatherId=random.choice([1, 3, 7, 8, 14]),\n",
    "    QualityLevel=\"Low\")\n",
    "settings.randomize_seeds()\n",
    "\n",
    "# Now we want to add a couple of cameras to the player vehicle.\n",
    "# We will collect the images produced by these cameras every\n",
    "# frame.\n",
    "\n",
    "# The default camera captures RGB images of the scene.\n",
    "camera0 = Camera('CameraRGB')\n",
    "# Set image resolution in pixels.\n",
    "camera0.set_image_size(800, 600)\n",
    "# Set its position relative to the car in meters.\n",
    "camera0.set_position(0.30, 0, 1.30)\n",
    "settings.add_sensor(camera0)\n",
    "\n",
    "# Let's add another camera producing ground-truth depth.\n",
    "camera1 = Camera('CameraDepth', PostProcessing='Depth')\n",
    "camera1.set_image_size(800, 600)\n",
    "camera1.set_position(0.30, 0, 1.30)\n",
    "settings.add_sensor(camera1)\n",
    "\n",
    "print(str(settings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from carla.client import CarlaClient\n",
    "client = CarlaClient(\"127.0.0.1\", 2000)\n",
    "client.connect()\n",
    "with open(\"./drive_interfaces/carla/yang_template.ini\", \"r\") as f:\n",
    "    #client.load_settings(settings)\n",
    "    client.load_settings(f.read())\n",
    "client.start_episode(0)\n",
    "measurements, sensor_data = client.read_data()\n",
    "client.send_control(VehicleControl())\n",
    "\n",
    "client.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with make_carla_client(\"127.0.0.1\", 2000) as client:\n",
    "    with open(\"./drive_interfaces/carla/yang_template.ini\", \"r\") as f:\n",
    "        #client.load_settings(settings)\n",
    "        client.load_settings(f.read())\n",
    "    client.start_episode(0)\n",
    "    measurements, sensor_data = client.read_data()\n",
    "    client.send_control(VehicleControl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measurements.player_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_converter.depth_to_array(sensor_data['DepthLeft']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=image_converter.labels_to_array(sensor_data['SegLeft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "b=a[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "image = scipy.misc.imresize(b, [30, 40], interp='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=sensor_data['DepthLeft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from carla import image_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=image_converter.depth_to_array(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measure, sensor ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "path= \"/scratch/yang/aws_data/carla_collect/1/2018726_default_RotationPitch=-15_WeatherId=10_4/data_00000.h5\"\n",
    "import h5py\n",
    "f=h5py.File(path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imdecode(f['CameraLeft'][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "a=Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ffmpeg -i data_00000.h5.CameraMiddle%04d.png -c:v libx264 out.mp4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= \"/scratch/yang/aws_data/carla_collect/1/2018726_default_RotationPitch=-15_WeatherId=10_5/data_00000.h5\"\n",
    "path = \"/data/yang/code/aws/scratch/carla_collect/1/2018727_default_RotationPitch=0_WeatherId=13_1/data_00000.h5\"\n",
    "path = \"/scratch/yang/aws_data/carla_collect/1/2018730_default_RotationPitch=0_WeatherId=01_1/data_00000.h5\"\n",
    "def sample_images_from_h5(path):\n",
    "    f=h5py.File(path, \"r\")\n",
    "    for key in f.keys():\n",
    "        if 'targets' not in key:\n",
    "            for imid in range(200):\n",
    "                data = f[key][imid]\n",
    "                if 'camera' in key.lower():\n",
    "                    ext = \".jpg\"\n",
    "                else:\n",
    "                    ext = \".png\"\n",
    "                out_name = path+\".\" + key + str(imid).zfill(4) + ext\n",
    "                with open(out_name, \"w\") as g:\n",
    "                    g.write(data)\n",
    "sample_images_from_h5(path)\n",
    "\n",
    "\"ffmpeg -i data_00000.h5.CameraMiddle%04d.png -c:v libx264 out.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 yang users 48M Jul 30 23:41 /scratch/yang/aws_data/carla_collect/1/2018730_default_RotationPitch=0_WeatherId=00_1/data_00000.h5\r\n"
     ]
    }
   ],
   "source": [
    "from subprocess import call\n",
    "for i in range(1):\n",
    "    prefix = \"/scratch/yang/aws_data/carla_collect/1/2018730_default_RotationPitch=0_WeatherId=\"+str(i).zfill(2)+\"_1/\"\n",
    "    path = prefix + \"data_00000.h5\"\n",
    "    ! ls -alh $path\n",
    "    sample_images_from_h5(path)\n",
    "    \n",
    "    call(\"ffmpeg -i \"+ prefix +\"data_00000.h5.CameraMiddle%04d.jpg -c:v libx264 \"+ prefix[:-1]+\".mp4\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after constructor\n",
      "('time eplapsed is ', 1.0166008472442627)\n",
      "('throttle', -1.0)\n",
      "('time eplapsed is ', 1.0324769020080566)\n",
      "('throttle', -1.0)\n",
      "('time eplapsed is ', 1.0310008525848389)\n",
      "('throttle', -1.0)\n",
      "('time eplapsed is ', 1.0606470108032227)\n",
      "('throttle', -1.0)\n",
      "('time eplapsed is ', 1.0337679386138916)\n",
      "('throttle', -1.0)\n",
      "('time eplapsed is ', 1.0316898822784424)\n",
      "('throttle', -1.0)\n",
      "('time eplapsed is ', 1.032865047454834)\n",
      "('throttle', -1.0)\n",
      "('time eplapsed is ', 1.0337390899658203)\n",
      "('throttle', -1.0)\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "class ControlInterface(object):\n",
    "    def __init__(self):\n",
    "        self._throttle = 1.0       \n",
    "        self.counter = 0        \n",
    "        self.start_loop()\n",
    "        self.last_time = time.time()\n",
    "\n",
    "    def set_throttle(self, new_throttle):\n",
    "        self._throttle = new_throttle\n",
    "\n",
    "    def start_loop(self):\n",
    "        self.counter += 1\n",
    "        if self.counter % 75 == 0:\n",
    "            print(\"time eplapsed is \", time.time()-self.last_time)\n",
    "            self.last_time = time.time()\n",
    "            print( \"throttle\", self._throttle)\n",
    "        threading.Timer(1.0/75, self.start_loop).start()\n",
    "        \n",
    "\n",
    "ctrl = ControlInterface()\n",
    "print(\"after constructor\")\n",
    "ctrl.set_throttle(-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def get_files_count_in_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        return 0\n",
    "    else:\n",
    "        pass\n",
    "import glob\n",
    "len(glob.glob(\"/data/yang/code/aws/scratch/carla_collect/1/2018731_default_RotationPitch=0_WeatherId=01_1/*.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash -c  '/scratch/yang/aws_data/carla_0.8.4/CarlaUE4.sh  -carla-server -carla-settings=/data/yang/code/aws/CIL_modular/drive_interfaces/carla/yang_template.ini -benchmark -fps=5' \n",
      "before spawnling\n"
     ]
    }
   ],
   "source": [
    "import os, threading\n",
    "cmd = ['bash', '-c', \" '/scratch/yang/aws_data/carla_0.8.4/CarlaUE4.sh  -carla-server -carla-settings=/data/yang/code/aws/CIL_modular/drive_interfaces/carla/yang_template.ini -benchmark -fps=5' \"]\n",
    "#cmd = cmd.split(\" \")\n",
    "#cmd = [x for x in cmd if x!=\"\" ]\n",
    "print(\" \".join(cmd))\n",
    "print(\"before spawnling\")\n",
    "t = threading.Thread(target = lambda : os.system(\" \".join(cmd)))\n",
    "t.start()       \n",
    "#! ps aux | grep $id0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4212"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(\"/data/yang/code/aws/scratch/carla_collect/1/*/data_*.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "path = \"/scratch/yang/aws_data/CIL_modular_data/matthias_data/RC025Val/data_00000.h5\"\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=h5py.File(path, \"r\")\n",
    "\n",
    "a=f['rgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "i+=3\n",
    "print(i)\n",
    "Image.fromarray(a[i, :,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "path =\"/scratch/yang/aws_data/carla_collect/1/default_ImageSizeX=700_WeatherId=10/data_00099.h5\"\n",
    "import h5py, time\n",
    "f = h5py.File(path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.00037789344787597656, 529249.716088328)\n",
      "(0.9612674713134766, 0.06985902786254883)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "start = time.time()\n",
    "t_decode = 0.0\n",
    "t_resize = 0.0\n",
    "for i in range(200):\n",
    "    a= f[\"CameraMiddle\"][i]\n",
    "    start = time.time()\n",
    "    decoded = cv2.imdecode(a, 1)                    \n",
    "    t_decode += time.time()-start\n",
    "    sz = (88,200)\n",
    "    start = time.time()\n",
    "    decoded = cv2.resize(decoded, (sz[1], sz[0]))\n",
    "    t_resize += time.time() -start\n",
    "delta = time.time()-start\n",
    "print(delta, 200/delta)\n",
    "print(t_decode, t_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.364"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "91*20*200 /1000/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*75/1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 600 out of 600 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "p = Parallel(n_jobs=8, backend=\"threading\", verbose=10)\n",
    "\n",
    "\n",
    "func = lambda x : cv2.imdecode(x, 1)\n",
    "if True:\n",
    "    height, width = 88, 200\n",
    "    func_previous = func\n",
    "    func = lambda x : cv2.resize(func_previous(x), (width, height))\n",
    "                \n",
    "func = lambda x : cv2.resize(cv2.imdecode(x, 1), (200, 88))        \n",
    "func = delayed(func)\n",
    "results = p(func(f[\"CameraMiddle\"][0]) for i in range(8*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "results = p(delayed(cv2.imdecode)(f[\"CameraMiddle\"][i], 1) for i in range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.concatenate((results[0], results[0]+5), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=cv2.resize(a, (200, 300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 200, 6)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image.fromarray(b[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _resize_BHWC(input, sz):\n",
    "    B, H, W, C = input.shape\n",
    "    input = np.transpose(input, (1, 2, 3, 0))\n",
    "    # now input has size H W C B\n",
    "    input = np.reshape(input, (H, W, C*B))\n",
    "    print(input.shape)\n",
    "    output = cv2.resize(input[:,:,:1000], (sz[1], sz[0]))\n",
    "    output = np.reshape(output, (sz[0], sz[1], C, B))\n",
    "    output = np.transpose(output, (3, 0, 1, 2))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stk = np.stack(results, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 576, 768, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 768, 600)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) /io/opencv/modules/imgproc/src/resize.cpp:3687: error: (-215) dsize.area() > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b0e42d88ce41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resize_BHWC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-a838acf91527>\u001b[0m in \u001b[0;36m_resize_BHWC\u001b[0;34m(input, sz)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.1) /io/opencv/modules/imgproc/src/resize.cpp:3687: error: (-215) dsize.area() > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "out = _resize_BHWC(stk, (200, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = lambda x: cv2.imdecode(x, 1)\n",
    "if hasattr(self._config, \"hack_resize_image\"):\n",
    "    height, width = self._config.hack_resize_image\n",
    "    func_previous = func\n",
    "    func = lambda x: cv2.resize(func_previous(x), (width, height))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
